# An√°lisis NLP con spaCy y Web Scraping

Este proyecto realiza un ejercicio pr√°ctico de procesamiento de lenguaje natural (PLN) utilizando **spaCy**, junto con t√©cnicas de **web scraping** y visualizaci√≥n. Se trabaja sobre una noticia de *Infobae* relacionada con tecnolog√≠a m√©dica.

## üß† Descripci√≥n

1. **Web Scraping**  
   Se obtiene el contenido de una noticia desde Infobae usando `BeautifulSoup`.

2. **Preprocesamiento del Texto**  
   - Eliminaci√≥n de etiquetas HTML irrelevantes.
   - Conversi√≥n a min√∫sculas y limpieza de signos de puntuaci√≥n.
   - Eliminaci√≥n de *stopwords* y palabras irrelevantes.

3. **Procesamiento con spaCy**  
   - Tokenizaci√≥n del texto.
   - Extracci√≥n y visualizaci√≥n de entidades nombradas (NER).
   - An√°lisis de dependencias sint√°cticas.

4. **Visualizaci√≥n**  
   Se generan visualizaciones con `displacy` y se construye una nube de palabras (`WordCloud`) con las palabras m√°s relevantes.

## üõ†Ô∏è Tecnolog√≠as Usadas

- `spaCy` + `es_core_news_lg`
- `BeautifulSoup`, `requests`
- `matplotlib`, `WordCloud`
- `nltk` para stopwords

## üìå Requisitos

```bash
pip install spacy beautifulsoup4 requests nltk wordcloud matplotlib
python -m spacy download es_core_news_lg

Tambi√©n es necesario descargar los recursos de stopwords de NLTK:
import nltk
nltk.download('stopwords')

‚ñ∂Ô∏è C√≥mo Ejecutar
1. Aseg√∫rate de tener Python y Jupyter Notebook instalados.
2. Abre el archivo 002_Spacy_Ejercicio_Practico.ipynb.
3. Ejecuta todas las celdas paso a paso.
4. Se mostrar√°n visualizaciones del an√°lisis de entidades y relaciones del texto, as√≠ como una nube de palabras.
